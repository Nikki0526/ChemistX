# -*- coding: utf-8 -*-
"""phase1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QqEA0MwoUKaBm0K_CiLT5ukgcKeDH42N
"""

pip install chromadb

pip install langchain

pip install openai==1.3.7

from google.colab import drive
drive.mount('/content/drive')

import os
#import getpass

os.environ["OPENAI_API_BASE"] = 'https://oneapi.xty.app/v1'
os.environ["OPENAI_API_KEY"] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'

os.chdir("/content/drive/MyDrive/Colab Notebooks/research/AI agent/100")

from langchain.document_loaders import TextLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

from langchain.schema.document import Document


documents =  Document(page_content='people, bus, road', metadata={"source": "local"})

db = Chroma.from_documents([documents], OpenAIEmbeddings(), collection_metadata={"hnsw:space": "ip"})

query = "people"
docs = db.similarity_search_with_relevance_scores(query,k=1)

from langchain.document_loaders import TextLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

# Load the document, split it into chunks, embed each chunk and load it into the vector store.
raw_documents = TextLoader('51d3bc1035b34be8c39a9f06b41a07f2f3f8_1.txt').load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)
#db = Chroma.from_documents(documents, OpenAIEmbeddings())
db = Chroma.from_documents(documents, OpenAIEmbeddings(), collection_metadata={"hnsw:space": "ip"})

query = "My input smiles is CN1C2=CC=CC(C3=CC=C4N=CC=CC4=C3)=C2C=N1, please help me generate python code to get 2-D similar molecule using PubChem API."
docs = db.similarity_search_with_relevance_scores(query,k=50)

query = "How to perform 2-D similarity search"
docs = db.similarity_search_with_score(query,k=50)

"""### inner product"""

query = "How to perform 2-D similarity search"
docs = db.similarity_search_with_relevance_scores(query,k=50)

for i in range(len(docs)):
  print(docs[i][1])

"""### cosine distance"""

query = "How to perform 2-D similarity search"
docs = db.similarity_search_with_relevance_scores(query,k=50)

for i in range(len(docs)):
  print(docs[i][1])

"""### L2 distance"""

query = "How to perform 2-D similarity search"
docs = db.similarity_search_with_relevance_scores(query,k=50)

for i in range(len(docs)):
  print(docs[i][1])

print(docs[0][0].page_content)

"""# prompt to GPT"""

file_list = []

import re

def extract_and_save_python_code(text, name, repeated_times):

    # Regular expression pattern for extracting Python code blocks
    pattern = r"```python(.*?)```"
    # Use re.DOTALL to match across multiple lines
    matches = re.findall(pattern, text, re.DOTALL)

    # Save each extracted code block to a separate .py file
    for i, code_block in enumerate(matches, 1):
        file_name = f"extracted_code_block_{name}_{repeated_times}_{i}.py"
        with open(file_name, 'w') as file:
            file.write(code_block.strip())
        print(f"Saved Python code to {file_name}")

    file_list.append(file_name)

    return matches

from openai import OpenAI

client = OpenAI(
    base_url="https://oneapi.xty.app/v1",
    api_key="sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
)

"""## zeroshot"""

def prompt_function_zeroshot():
  completion = client.chat.completions.create(
  model="gpt-4-32k",
  messages=[{"role": "system", "content": "You are a helpful assistant on chemistry."},
    {"role": "user", "content": '''My input smiles is "CN1C2=CC=CC(C3=CC=C4N=CC=CC4=C3)=C2C=N1", please help me generate python code to get similar molecule using PubChem API.
    '''}
  ],
  stream = True
)
  return completion

for i in range(10):
  completion = prompt_function_zeroshot()
  text_print = ""

  for chunk in completion:
    if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
      text_print = text_print + chunk.choices[0].delta.content

  extracted_code_blocks = extract_and_save_python_code(text_print, 'zeroshot', i)

"""## all document"""

def prompt_function_fewshot(content):
  completion = client.chat.completions.create(
  model="gpt-4-1106-preview",
  messages=[{"role": "system", "content": "You are a helpful assistant on chemistry."},
    {"role": "user", "content": f'''My input smiles is "CN1C2=CC=CC(C3=CC=C4N=CC=CC4=C3)=C2C=N1", please help me generate python code to get similar molecule using PubChem API. You can refer to: '{content}'.
    '''}
  ],
  stream = True
)
  return completion

from tqdm import tqdm

import time

time_list = []
for i in tqdm(range(10)):
  start_time = time.time()

  completion = prompt_function_fewshot(str(raw_documents[0]))
  text_print = ""

  for chunk in completion:
    if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
      text_print = text_print + chunk.choices[0].delta.content

  end_time = time.time()
  execution_time = end_time - start_time
  time_list.append(execution_time)

  extracted_code_blocks = extract_and_save_python_code(text_print, 'alldocument', i)
  print(time_list)

"""## topmatch"""

#time_list = []
for i in tqdm(range(10)):
  #start_time = time.time()

  completion = prompt_function_fewshot(docs[0][0].page_content)
  text_print = ""

  for chunk in completion:
    if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
      text_print = text_print + chunk.choices[0].delta.content

  #end_time = time.time()
  #execution_time = end_time - start_time
  #time_list.append(execution_time)

  extracted_code_blocks = extract_and_save_python_code(text_print, 'topmatch', i)
  #print(time_list)

"""# random"""

import random

random_integer = random.randint(0, 17)

print(random_integer)

time_list = []
for i in tqdm(range(1)):
  start_time = time.time()

  random_integer = random.randint(0, 17)
  random_slice = documents[random_integer].page_content
  completion = prompt_function_fewshot(random_slice)
  text_print = ""

  end_time = time.time()

  for chunk in completion:
    if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
      text_print = text_print + chunk.choices[0].delta.content

  execution_time = end_time - start_time
  time_list.append(execution_time)

  extracted_code_blocks = extract_and_save_python_code(text_print, 'random', 9)
  print(time_list)